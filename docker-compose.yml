# Docker Compose for local development and testing
# Mimics the Sevalla production environment

services:
  # FastAPI Backend (ML Model)
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: msl-api
    ports:
      - "8000:8000"
    volumes:
      # Mount models directory for easy updates without rebuilding
      - ./models:/app/models:ro
    environment:
      - MODEL_PATH=models/best.pt
      - CLASS_MAPPING_PATH=models/class_mapping.json
      - LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # Next.js Frontend
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: msl-web
    ports:
      - "3000:3000"
    environment:
      # Use Docker's internal networking to reach the API
      - BACKEND_URL=http://api:8000
      - NODE_ENV=production
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped

# Network for internal communication (similar to Sevalla private network)
networks:
  default:
    name: msl-network
